<!-- templates/components/step_01_data-ingestion.html -->

<div class="space-y-6 text-slate-600">

    <p class="text-sm leading-relaxed">
        The pipeline begins with the ingestion of two complementary data sources:
        a sentiment-labeled tweet corpus and a curated emoji polarity reference
        lexicon. Rather than merging these datasets directly, each serves a distinct
        role within the modeling workflow — tweets as supervised training samples,
        and emojis as symbolic sentiment references.
    </p>

    <div class="grid grid-cols-1 sm:grid-cols-2 gap-4">

        <div class="p-4 bg-slate-50 rounded-xl border border-slate-100">
            <h4 class="text-xs font-black uppercase tracking-widest text-slate-400 mb-2">
                Primary Corpus
            </h4>
            <ul class="text-xs space-y-1 font-mono text-slate-700">
                <li>• Emoji-bearing tweets</li>
                <li>• Binary sentiment labels</li>
                <li>• Short-form social text</li>
            </ul>
        </div>

        <div class="p-4 bg-slate-50 rounded-xl border border-slate-100">
            <h4 class="text-xs font-black uppercase tracking-widest text-slate-400 mb-2">
                Reference Lexicon
            </h4>
            <ul class="text-xs space-y-1 font-mono text-slate-700">
                <li>• Emoji / emoticon symbols</li>
                <li>• Polarity annotations</li>
                <li>• Sentiment reference mappings</li>
            </ul>
        </div>

    </div>

    <p class="text-xs italic text-slate-400">
        Ingestion establishes dataset roles early — preserving training integrity
        while enabling downstream symbolic sentiment referencing.
    </p>

</div>
