{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dc05c11b",
   "metadata": {},
   "source": [
    "# 7.0 Model Explainability & Deep Inference Logging\n",
    "**Project:** VibeCheck AI  \n",
    "**Status:** Post-Deployment Audit Phase\n",
    "\n",
    "## Overview\n",
    "In the previous notebooks (4.0 and 5.0), we trained a **Multinomial Naive Bayes** model and built a basic inference pipeline. However, for a production-grade system, \"knowing the label\" isn't enough. \n",
    "\n",
    "This notebook focuses on **XAI (Explainable AI)**. We will extract the internal statistical weights of the model to log exactly *why* a decision was made. This is crucial for debugging our limited dataset and verifying the impact of our emoji-amplification logic.\n",
    "\n",
    "### Key Objectives:\n",
    "1. Load production artifacts (Model & Vectorizer).\n",
    "2. Extract **Feature Log Probabilities** to identify decision drivers.\n",
    "3. Implement a **Deep Logging Function** that flags high-ambiguity predictions.\n",
    "4. Visualize the **Global Feature Importance** of our current vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca341fdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Artifacts loaded. Ready for deep logging.\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from emoji_sentiment_analysis.config import MODELS_DIR\n",
    "from emoji_sentiment_analysis.features import extract_emojis\n",
    "\n",
    "# Load the production artifacts verified in 4.0 and 5.0\n",
    "model = joblib.load(MODELS_DIR / \"sentiment_model.pkl\")\n",
    "vectorizer = joblib.load(MODELS_DIR / \"tfidf_vectorizer.pkl\")\n",
    "\n",
    "print(\"‚úÖ Artifacts loaded. Ready for deep logging.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8dc5264",
   "metadata": {},
   "source": [
    "## 1. The Decision Audit Engine\n",
    "The `generate_inference_log` function below transforms raw text into a rich data object. Unlike standard inference, this function:\n",
    "* **Calculates Feature Weights:** Subtracts the Negative log-probability from the Positive log-probability for every token in the input.\n",
    "* **Flags High Ambiguity:** Uses an **Entropy Threshold** (0.15) to identify cases where the model is \"guessing\" rather than \"knowing.\"\n",
    "* **Tracks Engine Input:** Captures the exact string (including amplified emojis) that the classifier processed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2ffe5653",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"raw_text\": \"I love this! \\ud83d\\ude0a\",\n",
      "  \"engine_input\": \"I love this! \\ud83d\\ude0a \\ud83d\\ude0a\\ud83d\\ude0a\\ud83d\\ude0a\\ud83d\\ude0a\\ud83d\\ude0a\",\n",
      "  \"prediction\": \"Positive\",\n",
      "  \"confidence\": 0.5723,\n",
      "  \"entropy_flag\": \"High Ambiguity\",\n",
      "  \"top_drivers\": [\n",
      "    {\n",
      "      \"token\": \"love\",\n",
      "      \"weight\": 0.3929,\n",
      "      \"sentiment_lean\": \"Positive\"\n",
      "    },\n",
      "    {\n",
      "      \"token\": \"this\",\n",
      "      \"weight\": -0.0658,\n",
      "      \"sentiment_lean\": \"Negative\"\n",
      "    }\n",
      "  ],\n",
      "  \"emoji_detected\": true\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "def generate_inference_log(text):\n",
    "    # 1. Pipeline Execution\n",
    "    emojis = extract_emojis(text)\n",
    "    engine_input = f\"{text} {emojis * 5}\"\n",
    "    vec = vectorizer.transform([engine_input])\n",
    "    \n",
    "    # 2. Probability Extraction (From 5.0 logic)\n",
    "    probs = model.predict_proba(vec)[0]\n",
    "    prediction = int(model.predict(vec)[0])\n",
    "    \n",
    "    # 3. Feature Importance Extraction\n",
    "    # feature_log_prob_ contains: [log_prob_neg, log_prob_pos]\n",
    "    feature_names = vectorizer.get_feature_names_out()\n",
    "    nonzero_indices = vec.nonzero()[1]\n",
    "    \n",
    "    feature_impacts = []\n",
    "    for idx in nonzero_indices:\n",
    "        token = feature_names[idx]\n",
    "        # Weight = LogProb(Pos) - LogProb(Neg). Positive favors Pos class.\n",
    "        weight = model.feature_log_prob_[1][idx] - model.feature_log_prob_[0][idx]\n",
    "        feature_impacts.append({\n",
    "            \"token\": token,\n",
    "            \"weight\": round(weight, 4),\n",
    "            \"sentiment_lean\": \"Positive\" if weight > 0 else \"Negative\"\n",
    "        })\n",
    "    \n",
    "    # 4. Construct the JSON-like log\n",
    "    log_entry = {\n",
    "        \"raw_text\": text,\n",
    "        \"engine_input\": engine_input,\n",
    "        \"prediction\": \"Positive\" if prediction == 1 else \"Negative\",\n",
    "        \"confidence\": round(float(np.max(probs)), 4),\n",
    "        \"entropy_flag\": \"High Ambiguity\" if abs(probs[0] - probs[1]) < 0.15 else \"Clear Signal\",\n",
    "        \"top_drivers\": sorted(feature_impacts, key=lambda x: abs(x['weight']), reverse=True)[:3],\n",
    "        \"emoji_detected\": len(emojis) > 0\n",
    "    }\n",
    "    \n",
    "    return log_entry\n",
    "\n",
    "# Test the logger\n",
    "test_log = generate_inference_log(\"I love this! üòä\")\n",
    "import json\n",
    "print(json.dumps(test_log, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e20147c3",
   "metadata": {},
   "source": [
    "## 2. Global Model Signal Analysis\n",
    "To understand the \"personality\" of our model, we can look at the **Feature Importance** across the entire dataset. \n",
    "\n",
    "By calculating the difference in log-probabilities across the whole vocabulary, we identify the specific tokens that the model considers its \"strongest evidence.\" This allows us to ensure that our emoji-weighting (w=5) is having the intended effect relative to standard vocabulary words like \"happy\" or \"thanks.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3fa4e7bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üî• Top 10 POSITIVE Signals in Model:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>happy</td>\n",
       "      <td>3.269052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>great</td>\n",
       "      <td>1.664616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>thanks</td>\n",
       "      <td>1.561104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>thank</td>\n",
       "      <td>1.480214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>thank you</td>\n",
       "      <td>1.480214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>smile</td>\n",
       "      <td>1.440196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>thanks for</td>\n",
       "      <td>1.431364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>our</td>\n",
       "      <td>1.421771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>out</td>\n",
       "      <td>1.379906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>for the</td>\n",
       "      <td>1.334843</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          token    weight\n",
       "48        happy  3.269052\n",
       "47        great  1.664616\n",
       "107      thanks  1.561104\n",
       "105       thank  1.480214\n",
       "106   thank you  1.480214\n",
       "101       smile  1.440196\n",
       "108  thanks for  1.431364\n",
       "84          our  1.421771\n",
       "85          out  1.379906\n",
       "40      for the  1.334843"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚ùÑÔ∏è Top 10 NEGATIVE Signals in Model:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>unhappy</td>\n",
       "      <td>-3.352139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>sad</td>\n",
       "      <td>-1.967292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>please</td>\n",
       "      <td>-1.331317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>miss</td>\n",
       "      <td>-1.269606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>because</td>\n",
       "      <td>-1.264431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>-1.190984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>him</td>\n",
       "      <td>-1.185950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>so</td>\n",
       "      <td>-1.150225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>koalas</td>\n",
       "      <td>-1.117758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>still</td>\n",
       "      <td>-1.096806</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       token    weight\n",
       "133  unhappy -3.352139\n",
       "96       sad -1.967292\n",
       "90    please -1.331317\n",
       "73      miss -1.269606\n",
       "14   because -1.264431\n",
       "0         10 -1.190984\n",
       "54       him -1.185950\n",
       "102       so -1.150225\n",
       "65    koalas -1.117758\n",
       "104    still -1.096806"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Map entire vocabulary\n",
    "vocab = vectorizer.get_feature_names_out()\n",
    "weights = model.feature_log_prob_[1] - model.feature_log_prob_[0]\n",
    "\n",
    "importance_df = pd.DataFrame({'token': vocab, 'weight': weights})\n",
    "\n",
    "print(\"üî• Top 10 POSITIVE Signals in Model:\")\n",
    "display(importance_df.sort_values('weight', ascending=False).head(10))\n",
    "\n",
    "print(\"\\n‚ùÑÔ∏è Top 10 NEGATIVE Signals in Model:\")\n",
    "display(importance_df.sort_values('weight', ascending=True).head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43c20b5d",
   "metadata": {},
   "source": [
    "## üìä Summary of Findings\n",
    "* **Interpretability:** We can now provide a \"Reasoning\" list for every prediction (e.g., \"üòä had a weight of +2.1\").\n",
    "* **Reliability:** The `entropy_flag` allows the system to warn users when a prediction is statistically weak (Confidence ~50-60%).\n",
    "\n",
    "## üöÄ Next Steps: Production Integration\n",
    "The logic developed in this notebook can now be ported to the production environment:\n",
    "1. **`predict.py`**: Update the core prediction script to include the `log_entry` generation.\n",
    "2. **`main.py`**: Save these logs to a `data/logs/inference_history.csv` for future retraining.\n",
    "3. **UI Update**: Display the `top_drivers` in the frontend so users understand the AI's \"thought process.\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
