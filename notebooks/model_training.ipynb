{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ead60b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# emoji_sentiment_analysis\\notebooks\\model_training.ipynb\n",
    "\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add the project's root directory to the Python path\n",
    "project_root = Path().resolve().parent\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.insert(0, str(project_root))\n",
    "\n",
    "import pandas as pd\n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from emoji_sentiment_analysis.config import PROCESSED_DATA_DIR, MODELS_DIR, TEXT_COL, TARGET_COL\n",
    "import re\n",
    "from loguru import logger\n",
    "\n",
    "# --- Model Training ---\n",
    "\n",
    "# 1. Load the processed data\n",
    "processed_data_path = PROCESSED_DATA_DIR / \"1k_data_processed.csv\"\n",
    "try:\n",
    "    df = pd.read_csv(processed_data_path)\n",
    "    logger.info(f\"Successfully loaded processed data from {processed_data_path}\")\n",
    "except FileNotFoundError:\n",
    "    logger.error(f\"File not found at {processed_data_path}. Please run the dataset script first.\")\n",
    "    raise\n",
    "\n",
    "# 2. Extract emojis from text\n",
    "# Use the same regex as the app to ensure consistency\n",
    "EMOJI_PATTERN = re.compile(\n",
    "    r'[\\U0001F600-\\U0001F64F\\U0001F300-\\U0001F5FF\\U0001F680-\\U0001F6FF\\U0001F700-\\U0001F77F\\U0001F780-\\U0001F7FF\\U0001F800-\\U0001F8FF\\U0001F900-\\U0001F9FF\\U0001FA00-\\U0001FA6F\\U0001FA70-\\U0001FAFF\\U00002702-\\U000027B0\\U000024C2-\\U0001F251]+',\n",
    "    flags=re.UNICODE\n",
    ")\n",
    "\n",
    "def extract_emojis(text):\n",
    "    return \" \".join(re.findall(EMOJI_PATTERN, str(text)))\n",
    "\n",
    "df['emojis'] = df[TEXT_COL].apply(extract_emojis)\n",
    "df['text_and_emojis'] = df[TEXT_COL].astype(str) + \" \" + df['emojis']\n",
    "\n",
    "# 3. Split data into training and testing sets\n",
    "X = df['text_and_emojis']\n",
    "y = df[TARGET_COL]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "logger.info(\"Data split into training and testing sets.\")\n",
    "\n",
    "# 4. Train the TF-IDF Vectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train_vectorized = vectorizer.fit_transform(X_train)\n",
    "logger.info(\"TF-IDF vectorizer trained successfully.\")\n",
    "\n",
    "# 5. Train the Logistic Regression model\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train_vectorized, y_train)\n",
    "logger.info(\"Logistic Regression model trained successfully.\")\n",
    "\n",
    "# 6. Save the trained model and vectorizer\n",
    "MODELS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "joblib.dump(model, MODELS_DIR / \"sentiment_model.pkl\")\n",
    "joblib.dump(vectorizer, MODELS_DIR / \"tfidf_vectorizer.pkl\")\n",
    "logger.success(f\"Trained model and vectorizer saved to {MODELS_DIR}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
